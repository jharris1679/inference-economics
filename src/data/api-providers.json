{
  "updatedAt": "2026-01-18",
  "note": "Prices per 1M tokens. Blended rate assumes 50% input, 50% output.",
  "sources": {
    "OpenAI": "https://openai.com/api/pricing/",
    "Anthropic": "https://www.anthropic.com/pricing",
    "Google": "https://ai.google.dev/gemini-api/docs/pricing",
    "Mistral": "https://mistral.ai/pricing",
    "Groq": "https://groq.com/pricing",
    "Together": "https://www.together.ai/pricing",
    "Fireworks": "https://fireworks.ai/pricing",
    "DeepInfra": "https://deepinfra.com/pricing",
    "Cerebras": "https://www.cerebras.ai/pricing",
    "Amazon Bedrock": "https://aws.amazon.com/bedrock/pricing/"
  },
  "providers": {
    "llama-3.1-8b": [
      { "name": "Groq", "inputPer1M": 0.05, "outputPer1M": 0.08 },
      { "name": "Together", "inputPer1M": 0.18, "outputPer1M": 0.18 },
      { "name": "Fireworks", "inputPer1M": 0.10, "outputPer1M": 0.10 },
      { "name": "DeepInfra", "inputPer1M": 0.05, "outputPer1M": 0.05 },
      { "name": "Amazon Bedrock", "inputPer1M": 0.22, "outputPer1M": 0.22 }
    ],
    "llama-3.1-70b": [
      { "name": "Groq", "inputPer1M": 0.59, "outputPer1M": 0.99 },
      { "name": "Together", "inputPer1M": 0.88, "outputPer1M": 0.88 },
      { "name": "Fireworks", "inputPer1M": 0.90, "outputPer1M": 0.90 },
      { "name": "DeepInfra", "inputPer1M": 0.10, "outputPer1M": 0.32 },
      { "name": "Amazon Bedrock", "inputPer1M": 0.72, "outputPer1M": 0.72 }
    ],
    "llama-3.1-405b": [
      { "name": "Together", "inputPer1M": 3.50, "outputPer1M": 3.50 },
      { "name": "Fireworks", "inputPer1M": 0.90, "outputPer1M": 0.90 },
      { "name": "DeepInfra", "inputPer1M": 1.79, "outputPer1M": 1.79 },
      { "name": "Amazon Bedrock", "inputPer1M": 2.40, "outputPer1M": 2.40 }
    ],
    "llama-4-scout": [
      { "name": "Groq", "inputPer1M": 0.11, "outputPer1M": 0.34 },
      { "name": "Together", "inputPer1M": 0.18, "outputPer1M": 0.59 },
      { "name": "Fireworks", "inputPer1M": 0.20, "outputPer1M": 0.60 },
      { "name": "DeepInfra", "inputPer1M": 0.08, "outputPer1M": 0.30 }
    ],
    "llama-4-maverick": [
      { "name": "Together", "inputPer1M": 0.27, "outputPer1M": 0.85 },
      { "name": "Groq", "inputPer1M": 0.50, "outputPer1M": 0.77 },
      { "name": "Fireworks", "inputPer1M": 0.45, "outputPer1M": 1.35 },
      { "name": "DeepInfra", "inputPer1M": 0.15, "outputPer1M": 0.60 }
    ],
    "qwen2.5-7b": [
      { "name": "Together", "inputPer1M": 0.30, "outputPer1M": 0.30 },
      { "name": "Fireworks", "inputPer1M": 0.20, "outputPer1M": 0.20 }
    ],
    "qwen2.5-32b": [
      { "name": "Groq", "inputPer1M": 0.29, "outputPer1M": 0.59 },
      { "name": "Together", "inputPer1M": 0.80, "outputPer1M": 0.80 },
      { "name": "Fireworks", "inputPer1M": 0.90, "outputPer1M": 0.90 }
    ],
    "qwen2.5-72b": [
      { "name": "Together", "inputPer1M": 1.20, "outputPer1M": 1.20 },
      { "name": "Fireworks", "inputPer1M": 0.90, "outputPer1M": 0.90 },
      { "name": "DeepInfra", "inputPer1M": 0.40, "outputPer1M": 0.45 }
    ],
    "qwen3-8b": [
      { "name": "Together", "inputPer1M": 0.20, "outputPer1M": 0.20 },
      { "name": "Fireworks", "inputPer1M": 0.15, "outputPer1M": 0.15 },
      { "name": "DeepInfra", "inputPer1M": 0.05, "outputPer1M": 0.08 },
      { "name": "Groq", "inputPer1M": 0.08, "outputPer1M": 0.08 }
    ],
    "qwen3-32b": [
      { "name": "Together", "inputPer1M": 0.60, "outputPer1M": 0.60 },
      { "name": "Fireworks", "inputPer1M": 0.45, "outputPer1M": 0.45 },
      { "name": "DeepInfra", "inputPer1M": 0.12, "outputPer1M": 0.18 },
      { "name": "Groq", "inputPer1M": 0.29, "outputPer1M": 0.59 }
    ],
    "qwen3-235b-a22b": [
      { "name": "Together", "inputPer1M": 0.20, "outputPer1M": 0.60 },
      { "name": "Fireworks", "inputPer1M": 0.22, "outputPer1M": 0.88 },
      { "name": "DeepInfra", "inputPer1M": 0.18, "outputPer1M": 0.54 },
      { "name": "Cerebras", "inputPer1M": 0.60, "outputPer1M": 1.20 }
    ],
    "deepseek-coder-33b": [
      { "name": "DeepInfra", "inputPer1M": 0.30, "outputPer1M": 0.30 }
    ],
    "deepseek-v3": [
      { "name": "Together", "inputPer1M": 0.60, "outputPer1M": 1.25 },
      { "name": "DeepInfra", "inputPer1M": 0.32, "outputPer1M": 0.89 },
      { "name": "Fireworks", "inputPer1M": 0.56, "outputPer1M": 1.68 }
    ],
    "deepseek-v3.2": [
      { "name": "Together", "inputPer1M": 0.60, "outputPer1M": 1.25 },
      { "name": "Fireworks", "inputPer1M": 0.56, "outputPer1M": 1.68 },
      { "name": "DeepInfra", "inputPer1M": 0.32, "outputPer1M": 0.89 }
    ],
    "deepseek-r1": [
      { "name": "Together", "inputPer1M": 3.00, "outputPer1M": 7.00 },
      { "name": "Fireworks", "inputPer1M": 1.35, "outputPer1M": 5.40 },
      { "name": "DeepInfra", "inputPer1M": 0.50, "outputPer1M": 2.15 }
    ],
    "deepseek-r1-32b": [
      { "name": "Together", "inputPer1M": 0.80, "outputPer1M": 0.80 },
      { "name": "Fireworks", "inputPer1M": 0.50, "outputPer1M": 0.50 },
      { "name": "DeepInfra", "inputPer1M": 0.15, "outputPer1M": 0.45 },
      { "name": "Groq", "inputPer1M": 0.29, "outputPer1M": 0.59 }
    ],
    "deepseek-r1-8b": [
      { "name": "Together", "inputPer1M": 0.20, "outputPer1M": 0.20 },
      { "name": "Fireworks", "inputPer1M": 0.20, "outputPer1M": 0.20 },
      { "name": "DeepInfra", "inputPer1M": 0.05, "outputPer1M": 0.08 },
      { "name": "Groq", "inputPer1M": 0.05, "outputPer1M": 0.08 }
    ],
    "gemma-3-2b": [
      { "name": "Groq", "inputPer1M": 0.04, "outputPer1M": 0.04 },
      { "name": "DeepInfra", "inputPer1M": 0.03, "outputPer1M": 0.03 }
    ],
    "gemma-3-9b": [
      { "name": "Groq", "inputPer1M": 0.10, "outputPer1M": 0.10 },
      { "name": "DeepInfra", "inputPer1M": 0.07, "outputPer1M": 0.07 },
      { "name": "Fireworks", "inputPer1M": 0.20, "outputPer1M": 0.20 }
    ],
    "gemma-3-27b": [
      { "name": "Groq", "inputPer1M": 0.20, "outputPer1M": 0.20 },
      { "name": "DeepInfra", "inputPer1M": 0.12, "outputPer1M": 0.12 },
      { "name": "Fireworks", "inputPer1M": 0.30, "outputPer1M": 0.30 }
    ],
    "gpt-oss-20b": [
      { "name": "OpenAI", "inputPer1M": 1.10, "outputPer1M": 4.40 },
      { "name": "Together", "inputPer1M": 0.05, "outputPer1M": 0.20 }
    ],
    "gpt-oss-120b": [
      { "name": "OpenAI", "inputPer1M": 2.50, "outputPer1M": 10.00 },
      { "name": "Together", "inputPer1M": 0.15, "outputPer1M": 0.60 }
    ],
    "kimi-k2": [
      { "name": "Moonshot", "inputPer1M": 1.00, "outputPer1M": 3.00 },
      { "name": "Together", "inputPer1M": 1.00, "outputPer1M": 3.00 }
    ],
    "sqlcoder-7b": [],
    "sqlcoder-34b": [],
    "sqlcoder-70b": []
  },
  "proprietaryAlternatives": {
    "small": {
      "description": "Models comparable to 7-8B parameter OSS models",
      "models": [
        { "name": "GPT-5 Nano", "provider": "OpenAI", "inputPer1M": 0.05, "outputPer1M": 0.40, "tokPerSec": 150, "contextWindow": 128000 },
        { "name": "Gemini 2.0 Flash", "provider": "Google", "inputPer1M": 0.10, "outputPer1M": 0.40, "tokPerSec": 300, "contextWindow": 1000000 },
        { "name": "Claude 3 Haiku", "provider": "Anthropic", "inputPer1M": 0.25, "outputPer1M": 1.25, "tokPerSec": 160, "contextWindow": 200000 },
        { "name": "Claude 3 Haiku", "provider": "Amazon Bedrock", "inputPer1M": 0.25, "outputPer1M": 1.25, "tokPerSec": 150, "contextWindow": 200000 }
      ]
    },
    "medium": {
      "description": "Models comparable to 30-70B parameter OSS models",
      "models": [
        { "name": "GPT-4o-mini", "provider": "OpenAI", "inputPer1M": 0.15, "outputPer1M": 0.60, "tokPerSec": 103, "contextWindow": 128000 },
        { "name": "Gemini 2.5 Flash", "provider": "Google", "inputPer1M": 0.15, "outputPer1M": 0.60, "tokPerSec": 274, "contextWindow": 1000000 },
        { "name": "Claude Haiku 4.5", "provider": "Anthropic", "inputPer1M": 1.00, "outputPer1M": 5.00, "tokPerSec": 150, "contextWindow": 200000 },
        { "name": "Mistral Small", "provider": "Mistral", "inputPer1M": 0.10, "outputPer1M": 0.30, "tokPerSec": 120, "contextWindow": 32000 }
      ]
    },
    "large": {
      "description": "Models comparable to 70B+ parameter OSS models",
      "models": [
        { "name": "GPT-5", "provider": "OpenAI", "inputPer1M": 1.25, "outputPer1M": 10.00, "tokPerSec": 100, "contextWindow": 256000 },
        { "name": "Gemini 3 Flash", "provider": "Google", "inputPer1M": 0.50, "outputPer1M": 3.00, "tokPerSec": 350, "contextWindow": 1000000 },
        { "name": "Claude Sonnet 4.5", "provider": "Anthropic", "inputPer1M": 3.00, "outputPer1M": 15.00, "tokPerSec": 90, "contextWindow": 200000 },
        { "name": "Claude Sonnet 4.5", "provider": "Amazon Bedrock", "inputPer1M": 3.00, "outputPer1M": 15.00, "tokPerSec": 85, "contextWindow": 200000 },
        { "name": "GPT-4o", "provider": "OpenAI", "inputPer1M": 2.50, "outputPer1M": 10.00, "tokPerSec": 80, "contextWindow": 128000 },
        { "name": "Mistral Large", "provider": "Mistral", "inputPer1M": 2.00, "outputPer1M": 6.00, "tokPerSec": 80, "contextWindow": 128000 }
      ]
    },
    "frontier": {
      "description": "Flagship models comparable to 400B+ or reasoning models",
      "models": [
        { "name": "Claude Opus 4.5", "provider": "Anthropic", "inputPer1M": 5.00, "outputPer1M": 25.00, "tokPerSec": 50, "contextWindow": 200000 },
        { "name": "Claude Opus 4.5", "provider": "Amazon Bedrock", "inputPer1M": 5.00, "outputPer1M": 25.00, "tokPerSec": 45, "contextWindow": 200000 },
        { "name": "o1", "provider": "OpenAI", "inputPer1M": 15.00, "outputPer1M": 60.00, "tokPerSec": 30, "contextWindow": 200000 },
        { "name": "o3-mini", "provider": "OpenAI", "inputPer1M": 1.10, "outputPer1M": 4.40, "tokPerSec": 60, "contextWindow": 200000 },
        { "name": "Gemini 2.5 Pro", "provider": "Google", "inputPer1M": 1.25, "outputPer1M": 10.00, "tokPerSec": 150, "contextWindow": 1000000 }
      ]
    }
  }
}
